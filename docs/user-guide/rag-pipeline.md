# RAG Pipeline

В этом руководстве описывается конвейер Retrieval Augmented Generation (RAG), используемый в Ollama PDF RAG.

## Обзор

Конвейер RAG объединяет поиск документов с генерацией языковой модели для предоставления точных ответов с учетом контекста:

1. Обработка запросов
2. Извлечение документов
3. Контекстное расширение
4. Генерация ответа

## Компоненты

### 1. Embeddings

- Используем Nomic's text embeddings
- Преобразует текстовые фрагменты в векторы
- Позволяет осуществлять семантический поиск

### 2. Vector Store

- ChromaDB для хранения векторов
- Эффективный поиск сходства  
- Постоянное хранение документов

### 3. Retriever

- Многозапросный поиск
- Семантический поиск
- Управление контекстным окном

### 4. Language Model

- Local Ollama models
- Ответы с учетом контекста
- Источник атрибуции

## Pipeline Flow

1. **User Query**
   - Question is received
   - Query is processed

2. **Retrieval**
   - Похожие фрагменты найдены
   - Контекст собран

3. **Generation**
   - Контекст введен
   - Ответ получен
   - Источники отслеживаются

## Оптимизация производительности

- `Chunk size` настройка размера фрагмента
- Качество встраивания
- Выбор модели
- Управление памятью

## Лучшие практики

1. **Формирование запроса**
   - Будьте конкретны
   - По одному вопросу за раз
   - Понятный язык

2. **Выбор модели**
   - Соответствие задаче
   - Рассмотрите ресурсы
   - Баланс скорость/качество

3. **Управление контекстом**
   - Мониторинг релевантности 
   - Настроить извлечение
   - Очистить устаревшие данные